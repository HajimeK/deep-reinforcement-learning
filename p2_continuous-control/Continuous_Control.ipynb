{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ddpg_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='./Reacher_Linux_Multi/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Start DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ddpg(agent, n_episodes=1000, max_t=300, print_every=100):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    average_scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        scores = np.zeros(num_agents)\n",
    "        #scores_window = deque(maxlen=print_every)  # mean scores from most recent episodes\n",
    "        moving_avgs = []                               # list of moving averages\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]        # send the action to the environment\n",
    "            next_states = env_info.vector_observations   # get the next state\n",
    "            rewards = env_info.rewards                   # get the reward\n",
    "            dones = env_info.local_done\n",
    "\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done)             \n",
    "            states = next_states\n",
    "            scores += rewards        \n",
    "            if np.any(dones):                                   # exit loop when episode ends\n",
    "                break\n",
    "\n",
    "        average_scores.append(np.mean(scores))\n",
    "        #scores_window.append(average_scores[-1])         # save mean score to window\n",
    "        #moving_avgs.append(np.mean(scores_window))    # save moving average\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, average_scores[-1]), end=\"\")\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, average_scores[-1]))\n",
    "        if average_scores[-1] > 30:\n",
    "            print('\\rEnvironment solved in {} episodes with an Average Score of {:.2f}'.format(i_episode, average_scores[-1]))\n",
    "            return average_scores\n",
    "            \n",
    "    return average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotscores(scores):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seach for better hyper parameters value\n",
    "\n",
    "First with some devault values, the \n",
    "\n",
    "| Hyper Parameter | Description |\n",
    "|-|-|\n",
    "| _BUFFER_SIZE | replay buffer size |\n",
    "| _BATCH_SIZE |  minibatch size |\n",
    "| _GAMMA | discount factor |\n",
    "| _TAU | for soft update of target parameters |\n",
    "| _LR_ACTOR | learning rate of the actor |\n",
    "| _LR_CRITIC | learning rate of the critic |\n",
    "| _WEIGHT_DECAY | L2 weight decay |\n",
    "| _mu | Ornstein-Uhlenbeck process |\n",
    "| _theta | Ornstein-Uhlenbeck process |\n",
    "| _sigma | Ornstein-Uhlenbeck process |\n",
    "| _actor_fc1_units | Actor Layer 1 units |\n",
    "| _actor_fc2_units |  Actor Layer 2 units |\n",
    "| _critic_fc1_units | Critic Layer 1 units |\n",
    "| _critic_fc2_units | Critic Layer 2 units |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_BUFFER_SIZE</th>\n",
       "      <th>_BATCH_SIZE</th>\n",
       "      <th>_GAMMA</th>\n",
       "      <th>_TAU</th>\n",
       "      <th>_LR_ACTOR</th>\n",
       "      <th>_LR_CRITIC</th>\n",
       "      <th>_WEIGHT_DECAY</th>\n",
       "      <th>_mu</th>\n",
       "      <th>_theta</th>\n",
       "      <th>_sigma</th>\n",
       "      <th>_actor_fc1_units</th>\n",
       "      <th>_actor_fc2_units</th>\n",
       "      <th>_critic_fc1_units</th>\n",
       "      <th>_critic_fc2_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _BUFFER_SIZE  _BATCH_SIZE  _GAMMA   _TAU  _LR_ACTOR  _LR_CRITIC  \\\n",
       "0        100000          128    0.99  0.001     0.0010      0.0010   \n",
       "1        100000          128    0.99  0.001     0.0001      0.0001   \n",
       "2        100000          128    0.90  0.001     0.0001      0.0001   \n",
       "3        100000          128    0.90  0.001     0.0001      0.0001   \n",
       "4        100000          128    0.90  0.001     0.0001      0.0001   \n",
       "\n",
       "   _WEIGHT_DECAY  _mu  _theta  _sigma  _actor_fc1_units  _actor_fc2_units  \\\n",
       "0              0    0    0.15     0.1               128               128   \n",
       "1              0    0    0.15     0.1               128               128   \n",
       "2              0    0    0.15     0.1               128               128   \n",
       "3              0    0    0.15     0.1                64                32   \n",
       "4              0    0    0.20     0.2                64                32   \n",
       "\n",
       "   _critic_fc1_units  _critic_fc2_units  \n",
       "0                128                128  \n",
       "1                128                128  \n",
       "2                128                128  \n",
       "3                 64                 32  \n",
       "4                 64                 32  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_hyperparameters = pd.read_csv('./hyperparameters.csv')\n",
    "df_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b55f65d19ba46c7bdd67dae4bd29e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_BUFFER_SIZE         100000.000\n",
      "_BATCH_SIZE             128.000\n",
      "_GAMMA                    0.990\n",
      "_TAU                      0.001\n",
      "_LR_ACTOR                 0.001\n",
      "_LR_CRITIC                0.001\n",
      "_WEIGHT_DECAY             0.000\n",
      "_mu                       0.000\n",
      "_theta                    0.150\n",
      "_sigma                    0.100\n",
      "_actor_fc1_units        128.000\n",
      "_actor_fc2_units        128.000\n",
      "_critic_fc1_units       128.000\n",
      "_critic_fc2_units       128.000\n",
      "Name: 0, dtype: float64\n",
      "Episode 100\tAverage Score: 0.22\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAUMUlEQVR4nO3df7BfdX3n8efLhFgqRX7d7rIEgQ64No5M0K9M3S3CIipsd4O1jsCCAsOUsZY6O4wdoGxrZcfZKWyLdaSz0IoF64LCVputAmKKK90lLpchjQYHjPiDILOEKlaaDgi+949z0n653OR+P0nO/UGej5nv5Hs+n3POfX8Shtf9nPP9nk+qCkmSJvWShS5AkrS0GBySpCYGhySpicEhSWpicEiSmixf6ALmwyGHHFJHHnnkQpchSUvKfffd90RVTc1s3yuC48gjj2R6enqhy5CkJSXJd2Zr91KVJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqMmhwJDk1yYNJNie5dJb+i5M8kGRjknVJjujbVye5J8mmvu+MsWP+NMm3kmzoX6uHHIMk6fkGC44ky4BrgNOAVcBZSVbN2O1+YFRVxwK3Alf27duAd1fVq4FTgQ8nOWDsuN+sqtX9a8NQY5AkvdCQM47jgc1V9XBVPQPcDJw+vkNV3VVV2/rN9cDKvv2hqvpG//57wOPA1IC1SpImNGRwHAY8Mra9pW/bkQuA22Y2JjkeWAF8c6z5Q/0lrKuTvHS2kyW5MMl0kumtW7e2Vy9JmtWiuDme5BxgBFw1o/1Q4BPA+VX1k775MuBVwOuBg4BLZjtnVV1XVaOqGk1NOVmRpD1lyOB4FDh8bHtl3/Y8SU4BLgfWVNXTY+37A58DLq+q9dvbq+qx6jwNfJzukpgkaZ4MGRz3AsckOSrJCuBMYO34DkmOA66lC43Hx9pXAJ8BbqyqW2ccc2j/Z4C3AV8bcAySpBmWD3Xiqno2yUXAHcAy4Pqq2pTkCmC6qtbSXZraD7ilywG+W1VrgHcCbwQOTnJef8rz+k9QfTLJFBBgA/CeocYgSXqhVNVC1zC40WhU09PTC12GJC0pSe6rqtHM9kVxc1yStHQYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqMmhwJDk1yYNJNie5dJb+i5M8kGRjknVJjujbVye5J8mmvu+MsWOOSvKV/pyfSrJiyDFIkp5vsOBIsgy4BjgNWAWclWTVjN3uB0ZVdSxwK3Bl374NeHdVvRo4FfhwkgP6vt8Drq6qo4EfABcMNQZJ0gsNOeM4HthcVQ9X1TPAzcDp4ztU1V1Vta3fXA+s7Nsfqqpv9O+/BzwOTCUJcDJdyADcALxtwDFIkmYYMjgOAx4Z297St+3IBcBtMxuTHA+sAL4JHAw8WVXPznXOJBcmmU4yvXXr1l0oX5I0m0VxczzJOcAIuGpG+6HAJ4Dzq+onLeesquuqalRVo6mpqT1XrCTt5ZYPeO5HgcPHtlf2bc+T5BTgcuDEqnp6rH1/4HPA5VW1vm/+W+CAJMv7Wces55QkDWfIGce9wDH9p6BWAGcCa8d3SHIccC2wpqoeH2tfAXwGuLGqtt/PoKoKuAt4R990LvAXA45BkjTDYMHRzwguAu4Avg58uqo2JbkiyZp+t6uA/YBbkmxIsj1Y3gm8ETivb9+QZHXfdwlwcZLNdPc8PjbUGCRJL5Tul/gXt9FoVNPT0wtdhiQtKUnuq6rRzPZFcXNckrR0GBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqMnFwJPnFJOf376eSHDVcWZKkxWqi4EjyAeAS4LK+aR/gz4YqSpK0eE064/hlYA3w9wBV9T3gZ4YqSpK0eE0aHM9UVQEFkORlw5UkSVrMJg2OTye5Fjggya8CXwT+eLiyJEmL1fJJdqqq/5rkzcDfAf8S+J2qunPQyiRJi9KcwZFkGfDFqvo3gGEhSXu5OS9VVdVzwE+SvHwe6pEkLXITXaoCngK+muRO+k9WAVTV+wapSpK0aE0aHH/evyRJe7lJb47fkGQF8Mq+6cGq+vFwZUmSFquJgiPJScANwLeBAIcnObeqvjxcaZKkxWjSS1W/D7ylqh4ESPJK4CbgdUMVJklanCb9AuA+20MDoKoeontelSRpLzPpjGM6yZ/wTw82PBuYHqYkSdJiNmlw/Brw68D2j9/eDfzRIBVJkha1SYNjOfCHVfUH8I/fJn/pYFVJkhatSe9xrAP2Hdvel+5BhzuV5NQkDybZnOTSWfovTvJAko1J1iU5Yqzv9iRPJvnLGcf8aZJvJdnQv1ZPOAZJ0h4waXD8VFU9tX2jf//TOzugn5VcA5wGrALOSrJqxm73A6OqOha4FbhyrO8q4F07OP1vVtXq/rVhwjFIkvaASYPj75O8dvtGkhHwD3McczywuaoerqpngJuB08d3qKq7qmpbv7keWDnWtw740YT1SZLmyaTB8R+BW5LcneRuuhC4aI5jDgMeGdve0rftyAXAbRPW86H+8tbVSWa915LkwiTTSaa3bt064WklSXPZaXAkeX2Sf15V9wKvAj4F/Bi4HfjWnioiyTnAiO7y1Fwu62t5PXAQ3VroL1BV11XVqKpGU1NTe6pUSdrrzTXjuBZ4pn//BuC36O5b/AC4bo5jHwUOH9te2bc9T5JTgMuBNVX19FwFV9Vj1Xka+DjdJTFJ0jyZKziWVdX3+/dnANdV1f+oqt8Gjp7j2HuBY5Ic1T8g8Uxg7fgOSY6jC6c1VfX4JAUnObT/M8DbgK9Ncpwkac+Y63scy5Isr6pngTcBF056bFU9m+Qi4A5gGXB9VW1KcgUwXVVr6S5N7Ud3/wTgu1W1BqC/l/IqYL8kW4ALquoO4JNJpugetrgBeE/bkCVJu2Ou4LgJ+F9JnqD7FNXdAEmOBn4418mr6vPA52e0/c7Y+1N2cuwJO2g/ea6fK0kazlyzhg8lWQccCnyhqqrvegnwG0MXJ0lafOZ85EhVrZ+l7aFhypEkLXaTfo9DkiTA4JAkNTI4JElNDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0MDklSE4NDktTE4JAkNTE4JElNDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0MDklSE4NDktTE4JAkNTE4JElNDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0GDY4kpyZ5MMnmJJfO0n9xkgeSbEyyLskRY323J3kyyV/OOOaoJF/pz/mpJCuGHIMk6fkGC44ky4BrgNOAVcBZSVbN2O1+YFRVxwK3AleO9V0FvGuWU/8ecHVVHQ38ALhgT9cuSdqxIWccxwObq+rhqnoGuBk4fXyHqrqrqrb1m+uBlWN964Afje+fJMDJdCEDcAPwtmHKlyTNZsjgOAx4ZGx7S9+2IxcAt81xzoOBJ6vq2bnOmeTCJNNJprdu3TphyZKkuSyKm+NJzgFGdJen9oiquq6qRlU1mpqa2lOnlaS93vIBz/0ocPjY9sq+7XmSnAJcDpxYVU/Pcc6/BQ5Isryfdcx6TknScIaccdwLHNN/CmoFcCawdnyHJMcB1wJrqurxuU5YVQXcBbyjbzoX+Is9WrUkaacGC45+RnARcAfwdeDTVbUpyRVJ1vS7XQXsB9ySZEOSfwyWJHcDtwBvSrIlyVv7rkuAi5Nsprvn8bGhxiBJeqF0v8S/uI1Go5qenl7oMiRpSUlyX1WNZrYvipvjkqSlw+CQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0MDklSE4NDktTE4JAkNTE4JElNDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0MDklSE4NDktTE4JAkNTE4JElNDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0MDklSE4NDktTE4JAkNTE4JElNDA5JUhODQ5LUZNDgSHJqkgeTbE5y6Sz9Fyd5IMnGJOuSHDHWd26Sb/Svc8fav9Sfc0P/+tkhxyBJer7lQ504yTLgGuDNwBbg3iRrq+qBsd3uB0ZVtS3JrwFXAmckOQj4ADACCrivP/YH/XFnV9X0ULVLknZsyBnH8cDmqnq4qp4BbgZOH9+hqu6qqm395npgZf/+rcCdVfX9PizuBE4dsFZJ0oSGDI7DgEfGtrf0bTtyAXDbhMd+vL9M9dtJMtvJklyYZDrJ9NatW9urlyTNalHcHE9yDt1lqasm2P3sqnoNcEL/etdsO1XVdVU1qqrR1NTUnitWkvZyQwbHo8DhY9sr+7bnSXIKcDmwpqqenuvYqtr+54+A/053SUySNE+GDI57gWOSHJVkBXAmsHZ8hyTHAdfShcbjY113AG9JcmCSA4G3AHckWZ7kkP7YfYB/B3xtwDFIkmYY7FNVVfVskovoQmAZcH1VbUpyBTBdVWvpLk3tB9zS36r4blWtqarvJ/nPdOEDcEXf9jK6ANmnP+cXgT8eagySpBdKVS10DYMbjUY1Pe2ndyWpRZL7qmo0s31R3ByXJC0dBockqclecakqyVbgOwtdR6NDgCcWuoh55pj3Do556Tiiql7wfYa9IjiWoiTTs11bfDFzzHsHx7z0ealKktTE4JAkNTE4Fq/rFrqABeCY9w6OeYnzHockqYkzDklSE4NDktTE4FgAEyype0S/lO7GfqnclWN9r0jyhSRf75fdPXI+a99VuznmK5Ns6sf8kR2twbKYJLk+yeNJZn0IZzof6f8+NiZ57VjfrMsmL3a7OuYkq5Pc0/8bb0xyxvxWvut259+5798/yZYkH52fiveQqvI1jy+6hzN+E/g5YAXwN8CqGfvcApzbvz8Z+MRY35eAN/fv9wN+eqHHNOSYgX8F/O/+HMuAe4CTFnpME4z5jcBrga/toP/f0i1cFuAXgK/07QcBD/d/Hti/P3ChxzPwmF8JHNO//xfAY8ABCz2eIcc81v+HdMtDfHShx9LycsYx/+ZcUhdYBfxV//6u7f1JVgHLq+pOgKp6qv5p6d3FbJfHTLfm/E/RBc5LgX2A/zd4xbupqr4MfH8nu5wO3Fid9cABSQ5lCS+bvKtjrqqHquob/Tm+BzwOLInV13bj35kkrwP+GfCF4SvdswyO+TfJkrp/A7y9f//LwM8kOZjuN7Mnk/x5kvuTXJVk2eAV775dHnNV3UMXJI/1rzuq6usD1zsfdvR30rrk8lIy59iSHE/3S8I357GuIc065iQvAX4feP+CVLWbDI7F6f3AiUnuB06kW/3wObr1U07o+19Pd+nnvAWqcU+bdcxJjgZ+nm4VyMOAk5OcsHBlaij9b+KfAM6vqp8sdD0Dey/w+arastCF7IrBFnLSDs25pG4/XX87QJL9gF+pqieTbAE2VNXDfd9n6a6bfmw+Ct8NuzPmXwXWV9VTfd9twBuAu+ej8AHt6O/kUeCkGe1fmreqhrXD/w6S7A98Dri8v6TzYrGjMb8BOCHJe+nuVa5I8lRVveCDI4uRM475N8mSuof0U1mAy4Drx449IMn2678nAw/MQ827a3fG/F26mcjyfuXHE4EXw6WqtcC7+0/d/ALww6p6jB0sm7yQhe5Bs465/2/iM3T3Am5d2BL3uFnHXFVnV9UrqupIutn2jUslNMAZx7yryZbUPQn4L0kK+DLw6/2xzyV5P7Cu/0jqfSyBpXN3Z8zArXQB+VW6G+W3V9X/nO8xtEpyE92YDulnih+gu7FPVf034PN0n7jZDGwDzu/7Zl02eX6r3zW7OmbgnXSfTjo4yXl923lVtWHeit9FuzHmJc1HjkiSmnipSpLUxOCQJDUxOCRJTQwOSVITg0OS1MTgkHYiyXNJNoy9dvpZ+yTvSfLuPfBzv53kkF047q1JPpjkoP7LktIe5/c4pJ37h6paPenO/Wf3F9IJdM/2OgH46wWuRS9SzjikXdDPCK5M8tUk/7d/phZJfrf/kiZJ3pduzZSNSW7u2w5K8tm+bX2SY/v2g9Ots7IpyZ/QPYZ7+886p/8ZG5JcO9uDLZOckWQD8D7gw3RfDD0/ydqZ+0q7y+CQdm7fGZeqxhcZ+mFVvQb4KN3/rGe6FDiuqo4F3tO3fRC4v2/7LeDGvv0DwF9X1avpHr/xCoAkPw+cAfzrfubzHHD2zB9UVZ8CjqNbF+I1dN+0P66q1uzO4KXZeKlK2rmdXaq6aezPq2fp3wh8sn8Y5Wf7tl8EfgWgqv6qn2nsT/fIjbf37Z9L8oN+/zcBrwPu7Z4yw75061XM5pV0Cz8BvKyqfjTB+KRmBoe062oH77f7JbpA+PfA5Ulesws/I8ANVXXZTndKpoFDgOVJHgAO7S9d/UZVLfUnCWuR8VKVtOvOGPvznvGO/km/h1fVXcAlwMvpHp99N/2lpiQnAU9U1d/RPdjxP/Ttp9EtGwuwDnhHkp/t+w5KcsTMQqpqRPdY8tOBK+keT77a0NAQnHFIO7dv/5v7drePPf76wCQbgaeBs2Yctwz4syQvp5s1fKRfX+R3gev747YB5/b7fxC4Kckm4P/QPU6eqnogyX8CvtCH0Y/pnhz8nVlqfS3dzfH3An+wO4OWdsan40q7IMm3gVFVPbHQtUjzzUtVkqQmzjgkSU2ccUiSmhgckqQmBockqYnBIUlqYnBIkpr8f+/kBc9jGOlFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_BUFFER_SIZE         100000.0000\n",
      "_BATCH_SIZE             128.0000\n",
      "_GAMMA                    0.9900\n",
      "_TAU                      0.0010\n",
      "_LR_ACTOR                 0.0001\n",
      "_LR_CRITIC                0.0001\n",
      "_WEIGHT_DECAY             0.0000\n",
      "_mu                       0.0000\n",
      "_theta                    0.1500\n",
      "_sigma                    0.1000\n",
      "_actor_fc1_units        128.0000\n",
      "_actor_fc2_units        128.0000\n",
      "_critic_fc1_units       128.0000\n",
      "_critic_fc2_units       128.0000\n",
      "Name: 1, dtype: float64\n",
      "Episode 5\tAverage Score: 0.11"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4f9fbd9b4a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_critic_fc1_units\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 int(row[\"_critic_fc2_units\"]))\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mplotscores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddpg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-4c8d66548eb9>\u001b[0m in \u001b[0;36mddpg\u001b[0;34m(agent, n_episodes, max_t, print_every)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/deep-reinforcement-learning/p2_continuous-control/ddpg_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/deep-reinforcement-learning/p2_continuous-control/ddpg_agent.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, experiences, gamma)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# Minimize the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/drlnd/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/drlnd/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "for index, row in tqdm(df_hyperparameters.iterrows()):\n",
    "    print(row)\n",
    "    agent = Agent(state_size, action_size, 2,\n",
    "                int(row[\"_BUFFER_SIZE\"]),\n",
    "                int(row[\"_BATCH_SIZE\"]),\n",
    "                row[\"_GAMMA\"],\n",
    "                row[\"_TAU\"],\n",
    "                row[\"_LR_ACTOR\"], \n",
    "                row[\"_LR_CRITIC\"],\n",
    "                row[\"_WEIGHT_DECAY\"],\n",
    "                row[\"_mu\"],\n",
    "                row[\"_theta\"],\n",
    "                row[\"_sigma\"],\n",
    "                int(row[\"_actor_fc1_units\"]),\n",
    "                int(row[\"_actor_fc2_units\"]),\n",
    "                int(row[\"_critic_fc1_units\"]),\n",
    "                int(row[\"_critic_fc2_units\"]))\n",
    "    plotscores(ddpg(agent, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guess\n",
    "\n",
    "LR for the critic granurality \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report version\n",
    "\n",
    "Batch Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "_BATCH_SIZE = 128        # minibatch size\n",
    "_GAMMA = 0.90            # discount factor\n",
    "_TAU = 1e-3              # for soft update of target parameters\n",
    "_LR_ACTOR = 1e-4         # learning rate of the actor \n",
    "_LR_CRITIC = 1e-4        # learning rate of the critic\n",
    "_WEIGHT_DECAY = 0        # L2 weight decay\n",
    "_mu=0.                   # Ornstein-Uhlenbeck noise parameters\n",
    "_theta=0.15              # Ornstein-Uhlenbeck noise parameters\n",
    "_sigma=0.1               # Ornstein-Uhlenbeck noise parameters\n",
    "_actor_fc1_units=64\n",
    "_actor_fc2_units=32\n",
    "_critic_fc1_units=64\n",
    "_critic_fc2_units=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=2,\n",
    "    BUFFER_SIZE = _BUFFER_SIZE,  # replay buffer size\n",
    "    BATCH_SIZE = _BATCH_SIZE,        # minibatch size\n",
    "    GAMMA = _GAMMA,            # discount factor\n",
    "    TAU = _TAU,              # for soft update of target parameters\n",
    "    LR_ACTOR = _LR_ACTOR,         # learning rate of the actor \n",
    "    LR_CRITIC = _LR_CRITIC,        # learning rate of the critic\n",
    "    WEIGHT_DECAY = _WEIGHT_DECAY,       # L2 weight decay\n",
    "    mu = _mu,\n",
    "    theta= _theta,\n",
    "    sigma= _sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 10.84\n",
      "Episode 150\tAverage Score: 10.66"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotscores(ddpg(agent, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 36.423499185871336\n"
     ]
    }
   ],
   "source": [
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = agent.act(states)                        # select an action (for each agent)\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
